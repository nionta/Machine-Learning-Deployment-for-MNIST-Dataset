{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_Gpm_U8ZLF4"
      },
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# 0.  Set‑up: installs and imports\n",
        "# ===============================================================\n",
        "!pip install --quiet onnx onnxruntime\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR          # bonus scheduler\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "import onnx, onnxruntime as ort\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9aK6_kOZjHl"
      },
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# 1.  Dataset — normalize pixels to [0,1]  \n",
        "# ===============================================================\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),                 # already scales to [0,1]\n",
        "])\n",
        "\n",
        "full_mnist = datasets.MNIST(root=\".\", download=True, train=True, transform=transform)\n",
        "\n",
        "# ===============================================================\n",
        "# 2.  Train / Test split — 2/3 vs 1/3 \n",
        "# ===============================================================\n",
        "train_len   = int(len(full_mnist) * 2/3)\n",
        "test_len    = len(full_mnist) - train_len\n",
        "train_set, test_set = random_split(full_mnist, [train_len, test_len])\n",
        "\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True,  num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_set,  batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XS53FaBeZ1Zn"
      },
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# 3.  CNN model with the required architecture \n",
        "# ===============================================================\n",
        "class MNIST_CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(           # ----- feature extractor -----\n",
        "            nn.Conv2d(1, 32, kernel_size=3),     # (28,28,1) -> (26,26,32)\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),                     # (13,13,32)\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3),    # (11,11,64)\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),                     # (5,5,64)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(         # ----- classifier -----\n",
        "            nn.Flatten(),                        # 5*5*64 = 1600\n",
        "            nn.Linear(1600, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(128, 10)                   # raw logits\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model  = MNIST_CNN().to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQ2q7jkcZ7Cu"
      },
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# 4.  Training hyper‑parameters \n",
        "# ===============================================================\n",
        "epochs       = 10\n",
        "lr           = 1e-3\n",
        "criterion    = nn.CrossEntropyLoss()\n",
        "optimizer    = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# BONUS 5.  Learning‑rate scheduler \n",
        "scheduler = StepLR(optimizer, step_size=3, gamma=0.3)   # decay LR every 3 epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWKoRS6qZ-9j"
      },
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# Training & evaluation loops\n",
        "# ===============================================================\n",
        "def run_epoch(loader, train=True):\n",
        "    model.train(mode=train)\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        if train:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        logits = model(x)\n",
        "        loss   = criterion(logits, y)\n",
        "\n",
        "        if train:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        correct += (preds == y).sum().item()\n",
        "        total   += y.size(0)\n",
        "\n",
        "    return total_loss / total, correct / total\n",
        "\n",
        "\n",
        "for epoch in range(1, epochs+1):\n",
        "    train_loss, train_acc = run_epoch(train_loader, train=True)\n",
        "    test_loss,  test_acc  = run_epoch(test_loader,  train=False)\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} | \"\n",
        "          f\"Train Loss {train_loss:.4f} Acc {train_acc:.3f} | \"\n",
        "          f\"Test Loss {test_loss:.4f}  Acc {test_acc:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fX6m9e-fcK-2"
      },
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# 6.  Export model to ONNX \n",
        "# ===============================================================\n",
        "dummy = torch.randn(1, 1, 28, 28, device=device)\n",
        "onnx_path = \"mnist_cnn.onnx\"\n",
        "torch.onnx.export(model, dummy, onnx_path,\n",
        "                  input_names=['input'], output_names=['logits'],\n",
        "                  dynamic_axes={'input': {0: 'batch'}, 'logits': {0: 'batch'}},\n",
        "                  opset_version=13)\n",
        "print(f\"ONNX model saved to {onnx_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hXHMJLQcQbY"
      },
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# 7.  Load ONNX model & test on 5 random images \n",
        "# ===============================================================\n",
        "# -- ONNX Runtime session\n",
        "ort_sess = ort.InferenceSession(onnx_path, providers=['CPUExecutionProvider'])\n",
        "\n",
        "# pick 5 random samples from *test_set*\n",
        "idx = torch.randint(0, len(test_set), (5,))\n",
        "images, labels = zip(*[test_set[i] for i in idx])\n",
        "images = torch.stack(images)        # (5,1,28,28)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# run inference\n",
        "logits = ort_sess.run(None, {'input': images.numpy()})[0]\n",
        "preds  = torch.tensor(logits).argmax(dim=1)\n",
        "\n",
        "# visual check\n",
        "fig, axs = plt.subplots(1, 5, figsize=(12,2))\n",
        "for i,(img, gt, pd) in enumerate(zip(images, labels, preds)):\n",
        "    axs[i].imshow(img.squeeze(), cmap='gray')\n",
        "    axs[i].set_title(f\"GT:{gt}  Pred:{pd}\", color=(\"green\" if gt==pd else \"red\"))\n",
        "    axs[i].axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKnFdxB6yFKQ"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(\"mnist_cnn.onnx\")   # pops a browser “Save as…” dialog"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
